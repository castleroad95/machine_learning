{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수 : 60000 개\n",
      "테스트셋 이미지 수 : 10000 개\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t3\t18\t18\t18\t126\t136\t175\t26\t166\t255\t247\t127\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t30\t36\t94\t154\t170\t253\t253\t253\t253\t253\t225\t172\t253\t242\t195\t64\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t49\t238\t253\t253\t253\t253\t253\t253\t253\t253\t251\t93\t82\t82\t56\t39\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t18\t219\t253\t253\t253\t253\t253\t198\t182\t247\t241\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t80\t156\t107\t253\t253\t205\t11\t0\t43\t154\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t14\t1\t154\t253\t90\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t139\t253\t190\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t11\t190\t253\t70\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t35\t241\t225\t160\t108\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t81\t240\t253\t253\t119\t25\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t45\t186\t253\t253\t150\t27\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t16\t93\t252\t253\t187\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t249\t253\t249\t64\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t46\t130\t183\t253\t253\t207\t2\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t39\t148\t229\t253\t253\t253\t250\t182\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t24\t114\t221\t253\t253\t253\t253\t201\t78\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t23\t66\t213\t253\t253\t253\t253\t198\t81\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t18\t171\t219\t253\t253\t253\t253\t195\t80\t9\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t55\t172\t226\t253\t253\t253\t253\t244\t133\t11\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t136\t253\t253\t253\t212\t135\t132\t16\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "class : 5 \n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "##############신경망으로 이미지 인식 ###############\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils \n",
    "import numpy \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# MNIST데이터셋 로드\n",
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()\n",
    "\n",
    "print(\"학습셋 이미지 수 : %d 개\" % (X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수 : %d 개\" % (X_test.shape[0]))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 코드로 확인\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%d\\t' % i)\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "#28X28의 2차원배열 => 784개의 1차원 배열 변환 reshape(총 샘플수, 1차원 속성의 수)\n",
    "#X_train.reshape(X_train[0].shape, 784)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_train = X_train.astype('float64')\n",
    "\n",
    "X_train = X_train / 255  #정규화\n",
    "\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255\n",
    "\n",
    "print(X_train[0])  #정규화 변환 확인\n",
    "\n",
    "# Y 클래스 값 확인\n",
    "print(\"class : %d \" % (Y_class_train[0]))\n",
    "\n",
    "# Y 클래스 값 one-hot encoder 변환\n",
    "Y_train = np_utils.to_categorical(Y_class_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_class_test, 10)\n",
    "\n",
    "print(Y_train[0])  #one-hot encoder 변환 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14869, saving model to ./model/01-0.1487.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14869 to 0.10799, saving model to ./model/02-0.1080.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10799 to 0.09880, saving model to ./model/03-0.0988.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09880 to 0.07341, saving model to ./model/04-0.0734.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07341 to 0.06971, saving model to ./model/05-0.0697.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06971 to 0.06756, saving model to ./model/06-0.0676.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06756 to 0.06505, saving model to ./model/07-0.0651.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06505 to 0.05937, saving model to ./model/08-0.0594.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05937 to 0.05888, saving model to ./model/09-0.0589.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05888\n",
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.0816 - accuracy: 0.9793\n",
      "\n",
      " Test Accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU1bn/8c9DEgIYLgKCCFSxFfuDElBQpKgN0iJqW6z1Vi2KaBGPyEGLB6m1pdrjpWpbtQiiRVql0mO1SpVTUEqkSlAuBxTECyJiRFSCXIKSkGT9/lgzZDKZCZNkLgn7+3699mv2dc0zOzv72de1zDmHiIgEV4tMByAiIpmlRCAiEnBKBCIiAadEICIScEoEIiIBl53pAOqrc+fO7phjjmnQsnv37uWwww5LbkAp0lxiVZzJ11xiVZzJleo4V61atd05d0TMic65ZtUNHDjQNdSSJUsavGy6NZdYFWfyNZdYFWdypTpOYKWLs1/VpSERkYBTIhARCTglAhGRgGt2N4tFpOnZv38/xcXF7Nu3L9Oh1NK+fXs2bNiQ6TAOKllxtmrVih49epCTk5PwMkoEItJoxcXFtG3blmOOOQYzy3Q4NezZs4e2bdtmOoyDSkaczjlKSkooLi6mV69eCS+XsktDZjbbzD41s3VxppuZ3W9mG83sdTM7MVWxiEhq7du3j06dOjW5JBA0ZkanTp3qfWaWynsEc4CRdUw/Czgu1I0DZqQwFpFAKCqCO+7wn+kuIzIJlJbCxx/7z4ZKVhklJS2bRBzpKqMhyThll4acc0vN7Jg6ZhkF/Dn0fOtyM+tgZt2ccx+nKiY5NBUVQWEhFBTAkCHNv4y5c79Cbm79yygqguHDobwcWraExYszU0ZpKbzzDlRVQYsW0Ls35OVlsoyW7NjRFOLIbBl1yeQ9gu7AhxHDxaFxtRKBmY3DnzXQtWtXCgsLG/SFpaWlDV423ZpDrOvXt+O117qyfv1q+vbd3eAy1qzpwIABOxtUxvr17fjpT/uzf38LcnKquPfetTHLqWt9JlpGMuJIrIxjeOyxynqXMXfuVygr60VVlVFWVsXs2ZspK9tSrxjqU0bkOm3fvj179uwB/BF4VVVLwKiqcmzfXo5z5fWKI4hlVFZWHliHjY1j37599dp/ZDIRxDp/idlKjnNuFjALYNCgQa6goKBBX1hYWEhDl023VMfa2KPXoiK48UYoK3M8+aQ1+OjzxhsbfwRbUeGPlCoqsti9+0Rirba61meiZSQjjsTLoN5l5ObC3Lnh9dmCsWOPZciQY+sVQ33KiFynGzZsOHCj0wx27AgfvRqdO+eSl5dbrzjqW0ZJSQnDhw8HYNu2bWRlZdGp0xGUlcGcOa+Sm5tbZxmFhYW0bNmSb37zm/WOY/PmzSxbtoxLLrkk7m9ZtKiQxx67h/vuey5uHHXdLK7v+mjVqhUnnHBC3OnRMpkIioGeEcM9gK0ZiqVZScZOvLGn/4WFfvmqKqO83A83tIzKShpcRkGB/w3h39KQ3NnUyigrq6Jlyxb1LmPIEP+3bMy2kYwy8vL8pYs9e6Bt2zouYdSxISdcRkinTp1Ys2YNANOmTSMvL4/JkydTWgrbt5fRuXPdZRQWFpKXl1crESQSx+bNm/nLX/4SNxHk5UHPntCqVcMv6dR3fdRXJhPBfGCCmc0DBgO7gnB/oCntxJOxA27oTiuyjMbsPJvKzi+ZZcyevTl0JN6wMhp6fyJpZUyaRN6aNdS5r9q1C15/vfqid34+tG9fY5a8UAfAgAHw+9/XK4xVq1Zxww03sHv3brp06cKcOXPo1q0b999/PzNnziQ7O5s+ffpw5513MnPmTLKysnj88cd54IEH2LZtG7/61a/Iysqiffv2LF26lMrKSm688SYKCwspKyvj2muv5eqrr+amm25iw4YNDBgwgMsvv5zrr7++ViytW/uzrbw82LFjB2PHjmXTpk20adOGWbNmkZ+fz8svv8zUqVMBf8N36dKllJaWctFFF7F7924qKiqYMWMGp512Wr3WQyJSlgjM7AmgAOhsZsXAL4EcAOfcTGABcDawEfgCuCJVsTQVTW0nnowdcGN3Wo3deYbLyfjOL4lllJVtqfclnWZn1y6fBMB/7tpVKxE0hnOO6667jmeffZZWrVqxYMECbr75ZmbPns2dd97J+++/T25uLjt37qRDhw6MHz/+wFkEQL9+/Vi4cCHdu3dn586dAPzxj3+kffv2rFixgrKyMoYOHcqIESO48847ueeee3juuecSiu2Xv/wlJ5xwAs888wz/+te/uOyyy1izZg33338/06dPZ+jQoZSWltKqVStmzZrFmWeeyc0330xlZSVffPFF0tZRpFQ+NfSjg0x3wLWp+v5UaOzRfFPbiSdjB9zYnVYydp7SxCRy5B59VDR3blI3hLKyMtatW8d3vvMdqqqqcM7RrVs3APLz87n00ks599xzOffcc2MuP3ToUMaMGcOFF17IeeedB8CiRYt4/fXX+dvf/gbArl27ePfdd2nZsmW9Ynv55Zd56qmnADjjjDMoKSlh165dnHLKKdxwww1ceumlnHfeefTo0YOTTjqJsWPHsn//fs4991wGDBjQ0FVSJ71ZnKBkHM03tZ24dsCSMcnakONwztG3b1+Kiopq3YR9/vnnWbp0KfPnz+e2225j/fr1tZafOXMmr776Ks8//zwDBgxgzZo1OOd44IEHOPPMM2vMW9+n+/wxcE1mxg033MB5553HggULOOWUU3jxxRc5/fTTWbp0Kc8//zyjR4/mxhtv5LLLLqvX9yVClc4lKNbRfH2Ft/3bbmtYIoksZ+pU7cilmUvhhpybm8tnn31GUeituP3797N+/Xqqqqr48MMPGTZsGL/5zW/YuXMnpaWltG3btsajm++99x6DBw/m1ltvpXPnznz44YeceeaZzJgxg/379wPwzjvvsHfv3lrLHszpp5/O3LlzAZ9EOnfuTLt27di0aRP9+vVjypQpDBo0iLfeeosPPviALl268JOf/IQrr7yS1atXJ3EtVdMZQYKScTQPOhIXSYcWLVrwt7/9jYkTJ/L5559TVVXFpEmT6N27Nz/+8Y/ZtWsXzjmuv/56OnTowPe+9z3OP/98nn32WR544AF+97vf8e677+KcY/jw4fTv35/8/Hw2b97MiSeeiHOOI444gmeeeYb8/Hyys7Pp378/Y8aMiXmzONK0adO44ooryM/Pp02bNvzpT38C4MEHH+SVV14hKyuLPn36cNZZZzFv3jzuvvtucnJyyMvL489//nNqVli8FmuaapfJFsqWLXPu9tv9Z6qpVaXkai5xOtd8Yo2M880338xcIAexe/fuTIeQkGTGGevvQR0tlOmMoB50NC8ihyIlAhGRJFm4cCFTpkypMa5Xr178/e9/z1BEiVEiEBFJkjPPPLPWU0XNgZ4aEhEJOCUCEZGAC0wiCNfz3pgGO0REDkWBSATht4Jnz+7F8OGNa71JRORQE4hEEKvKZBE5dJSUlDBgwAAGDBjAkUceSffu3Q8Ml5fX3ZDMypUrmThxYlLjmTNnDlu31l2rfkFBAStXrkzq9zZUIJ4aSkaVySKSXMlo2jMsXnsE4Bt8qaioIDs79u5u0KBBDBo0qHEBRJkzZw7f+MY3OOqoo5JabqoEIhEko8pkEUnMpEkQ2ifHlUBzBDU0oDkCxowZQ8eOHVm5ciUnnXQSF110EZMmTeLLL7+kdevWPProoxx//PEUFhYeqEZ62rRpbNmyhU2bNrFlyxYmTZrExIkT2bt3LxdeeCHFxcVUVlZyyy23cNFFFx1o86C0tJTOnTszZ84cXnnlFVauXMmll15K69atKSoqonXr1nXG+sQTT/DrX/8aM+Occ87hrrvuorKykiuvvJKVK1diZowdO5brr7++VnsK8+bNq9+KiSEQiQACVM+7SDOQ4uYIDnjnnXeYP38+HTp0YPfu3SxdupTs7GxefPFFfvaznx2oDjrSW2+9xZIlS9izZw/HH38811xzDf/85z856qijeP7550Px72L//v0H2jw44ogj+Otf/3qgzYM//OEP3HPPPQmdaWzdupUpU6bw0ksv0bNnT0aMGMEzzzxDz549+eijj1i3bh3AgXYRottTSIbAJAIRSY8m0BzBARdccAFZWVmA33lffvnlvPvuu5jZgVpEo51zzjnk5uaSm5tLly5d+OSTT+jXrx+TJ09mypQpfPe73+W0005j3bp1B9o8AN/4fLjNg/pYsWIFBQUFdO7cmezsbC699FKWLl3KLbfcwqZNm7juuus455xzGDFiBJBYewr1FYibxSLStCSrSvaDOeywww7033LLLQwbNox169bxj3/8g3379sVcJje3ulH4rKwsKioq6N27N6tWraJfv35MnTqVW2+99UCbB2vWrGHNmjW88cYbLFq0qN4xuhjtEwAcfvjhrF27loKCAqZPn85VV10F+PYUrr32WlatWsXAgQOpqKio93dGUyIQkYxId7sau3btonv37oC/mVsfW7dupU2bNvz4xz9m8uTJrF69muOPPz5mmwdAvdooGDx4MC+99BIlJSVUVlbyxBNP8K1vfYvt27dTVVXFD3/4Q2677TZWr14dtz2FxtKlIREJhP/6r//i8ssv57e//S1nnHFGvZZ94403uPHGG2nRogU5OTnMmDGDli1bHmjzYNeuXVRUVDBp0iT69u3LmDFjGD9+fEI3i7t168Ydd9zBOeecg5lx9tlnM2rUKNauXcsVV1xBVehmyh133EFlZWXM9hQaLV791E21y2R7BOnUXGJVnMnXXGJVewTJlcn2CHRpSEQk4HRpSEQkhX7wgx/w/vvv1xh31113NanqqpUIRCQpnHOYWabDaHLS3SiNi/MUUl10aUhEGq1Vq1aUlJQ0aCckyeOco6SkhFatWtVrOZ0RiEij9ejRg+LiYj777LNMh1LLvn376r1jzIRkxdmqVSt69OhRr2WUCESk0XJycujVq1emw4ipsLCQE044IdNhHFQm49SlIRGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBLaSIws5Fm9raZbTSzm2JMb29m/zCztWa23syuSGU8IiJSW8oSgZllAdOBs4A+wI/MrE/UbNcCbzrn+gMFwL1m1jJVMYmISG2pPCM4GdjonNvknCsH5gGjouZxQFvz76XnATuAxreyICIiCbNUvRJuZucDI51zV4WGRwODnXMTIuZpC8wHvg60BS5yzj0fo6xxwDiArl27DmxoY82lpaXk5eU1aNl0ay6xKs7kay6xKs7kSnWcw4YNW+Wci92Icrz6qRvbARcAj0QMjwYeiJrnfOB3gAFfA94H2tVVrtojaFoUZ/I1l1gVZ3KlOk4y1B5BMdAzYrgHsDVqniuAp0Nxbgwlgq+nMCYREYmSykSwAjjOzHqFbgBfjL8MFGkLMBzAzLoCxwObUhiTiIhESVmlc865CjObACwEsoDZzrn1ZjY+NH0mcBswx8zewF8emuKc256qmEREpLaU1j7qnFsALIgaNzOifyswIpUxiIhI3fRmsYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMApEYiIBFxKE4GZjTSzt81so5ndFGeeAjNbY2brzeylVMYjIiK1ZaeqYDPLAqYD3wGKgRVmNt8592bEPB2AB4GRzrktZtYlVfGIiEhsqTwjOBnY6Jzb5JwrB+YBo6LmuQR42jm3BcA592kK4xERkRjMOZeags3Oxx/pXxUaHg0Mds5NiJjn90AO0BdoC9znnPtzjLLGAeMAunbtOnDevHkNiqm0tJS8vLwGLZtuzSVWxZl8zSVWxZlcqY5z2LBhq5xzg2JOdM6lpAMuAB6JGB4NPBA1zx+A5cBhQGfgXaB3XeUOHDjQNdSSJUsavGy6NZdYFWfyNZdYFWdypTpOYKWLs19N2T0C/H2BnhHDPYCtMebZ7pzbC+w1s6VAf+CdFMYlIiIRUnmPYAVwnJn1MrOWwMXA/Kh5ngVOM7NsM2sDDAY2pDAmERGJkrIzAudchZlNABYCWcBs59x6Mxsfmj7TObfBzP4JvA5U4S8lrUtVTCIiUlsqLw3hnFsALIgaNzNq+G7g7lTGISIi8enNYhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJuIQSgZn9p5m1M++PZrbazEakOjgREUm9RM8IxjrndgMjgCOAK4A7UxaViIikTaKJwEKfZwOPOufWRowTEZFmLNFEsMrMFuETwUIza4uvJE5ERJq5RCuduxIYAGxyzn1hZh3xl4dERKSZS/SMYAjwtnNup5n9GPg5sCt1YYmISLokmghmAF+YWX/gv4APgFptC4uISPOTaCKoCLV5OQrfwPx9+MbmRUSkmUv0HsEeM5uKb4D+NDPLAnJSF5aIiKRLomcEFwFl+PcJtgHdUatiIiKHhIQSQWjnPxdob2bfBfY553SPQETkEJBoFRMXAq8BFwAXAq+a2fmpDExERNIj0XsENwMnOec+BTCzI4AXgb+lKjAREUmPRO8RtAgngZCSeiwrIiJNWKJnBP80s4XAE6Hhi4AFqQlJRETSKaFE4Jy70cx+CAzFVzY3yzn395RGJiIiaZHoGQHOuaeAp1IYi4iIZECdicDM9gAu1iTAOefapSQqERFJmzoTgXNO1UiIiBzi9OSPiEjAKRGIiAScEoGISMApEYiIBFxKE4GZjTSzt81so5ndVMd8J5lZpeovEhFJv5QlglCbBdOBs4A+wI/MrE+c+e4CFqYqFhERiS+VZwQnAxudc5ucc+XAPHwLZ9Guw7+o9mmMaSIikmLmW6BMQcH+Ms9I59xVoeHRwGDn3ISIeboDfwHOAP4IPOecq1WjqZmNA8YBdO3adeC8efMaFFNpaSl5eXkNWjbdmkusijP5mkusijO5Uh3nsGHDVjnnBsWalnAVEw1gMcZFZ53fA1Occ5VmsWYPLeTcLGAWwKBBg1xBQUGDAiosLKShy6Zbc4lVcSZfc4lVcSZXJuNMZSIoBnpGDPcAtkbNMwiYF0oCnYGzzazCOfdMCuMSEZEIqUwEK4DjzKwX8BFwMXBJ5AzOuV7hfjObg780pCQgIpJGKUsEzrkKM5uAfxooC5jtnFtvZuND02em6rtFRCRxqTwjwDm3gKgGbOIlAOfcmFTGIiIisenNYhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYALTCIoKoJHHz2GoqJMRyIi0rSktNK5pqKoCAoKoLz8aP7nf+Bf/4IhQzIdlYhI0xCIM4LCQqisBDDKyvywiIh4gUgEBQXQsiWAwzno1y/DAYmINCGBSARDhsDixXDhhcWYwcsvZzoiEZGmIxD3CMAng7Ky9zDryYMPwk03QYcOmY5KRCTzAnFGEGnqVNizB6ZPz3QkIiJNQ+ASQf/+cPbZ8PvfwxdfZDoaEZHMC1wiAH9WsH07PPJIpiMREcm8QCaCU0/13T33QHl5pqMREcmsQCYCgJ/9DD78EP7yl0xHIiKSWYFNBCNHwoABcOed4ZfNRESCKbCJwMw/Qvr22/DMM5mORkQkcwKbCADOPx++9jW44w5wLtPRiIhkRqATQVYWTJkCq1bBiy9mOhoRkcwIdCIAGD0ajjoKbr8905GIiGRG4BNBbi789Ke+RtLlyzMdjYhI+gU+EQCMGwcdO/p7BSIiQaNEAOTlwcSJMH8+rFuX6WhERNJLiSDkuuvgsMP8ewUiIkGS0kRgZiPN7G0z22hmN8WYfqmZvR7qlplZ/1TGU5eOHeHqq2HePHj//UxFISKSfilLBGaWBUwHzgL6AD8ysz5Rs70PfMs5lw/cBsxKVTyJuOEG/0jp3XdnMgoRkfRK5RnBycBG59wm51w5MA8YFTmDc26Zc+7z0OByoEcK4zmo7t3h8sth9mzYti2TkYiIpI+5FL1Sa2bnAyOdc1eFhkcDg51zE+LMPxn4enj+qGnjgHEAXbt2HThv3rwGxVRaWkpeXl6d83z0UWsuu+xkLrzwQ66+elODvicZEom1KVCcyddcYlWcyZXqOIcNG7bKOTco5kTnXEo64ALgkYjh0cADceYdBmwAOh2s3IEDB7qGWrJkSULzXXyxc23bOrdjR4O/qtESjTXTFGfyNZdYFWdypTpOYKWLs19N5aWhYqBnxHAPYGv0TGaWDzwCjHLOlaQwnoTddJOasxSR4EhlIlgBHGdmvcysJXAxMD9yBjP7CvA0MNo5904KY6mXcHOW992n5ixF5NCXskTgnKsAJgAL8Zd9/sc5t97MxpvZ+NBsvwA6AQ+a2RozW5mqeOpLzVmKSFBkp7Jw59wCYEHUuJkR/VcBtW4ONwWnngqnneabsxw/Hlq2zHREIiKpoTeL6zB1qm/Ocu7cTEciIpI6SgR1CDdnedddas5SRA5dwUkEs2aRP3kyzEr85WU1ZykiQRCMRDBrFlx9NYevWuUrFKrHc6Hh5ixvv13NWYrIoSkYieCppwCw8PANN8C990Jp6UEXDTdnuXo1vPBC6kIUEcmUYCSCH/4QgAMH9MceC5Mnw1e+Ar/6FezYUefi4eYs1XCNiByKgpEIxo2Dhx7i80GD4KGHYMMG3y7l6afDtGlw9NFw443w8ccxF8/N9XmjsBCuuQaKitIavYhISgUjEQCMG8frd9/tkwLA4MH+DvAbb8CoUfDb30KvXn5PH6NBgvx8/zlzJgwfrmQgIoeO4CSCeL7xDXj8cXjnneo6qI87zl8PevPNA7O99pp/igjgyy/h4Yd181hEDg1KBGFf/aq/bLRpE/znf8LTT0PfvnDeebBiBQUF0KoVtGjhE8Kjj8LQobBokRKCiDRvSgTRunf3TxRt2QK/+AUsWQInn8yQX45g8aj7+fWxs1ly/XxmzIDiYjjzTF8dxQsvKCGISPOkRBBPp07+iaItW+A3v4Hlyxky7z+ZuvFKvvXbUYx/egTvTnyAGVetYsvGMkaMgFOHVikhiEizk9JK5w4Jbdv6J4oWLoTFi6vHL15M7gsvMB64gpbMZiy3F/2MESN6MjRvDdPy/87wASVYzx7+LKNH6HPhQnjuOf9Ia/jGtYhIBikRJOrCC2smghkz/GvHxcXkFhdzzUcfMXbzo8wuPJbbV5/Jd5b9ilNfLWJa5c85g39Vv8wWtmgR/N//wd13QzNoRk9EDl1KBIkKH70/9VTNo/mOHQ88W5oLXAOMLYM//hFuv30I3/5oMacO/IJpP3qHMx4dja1fV13mzJn+KaVhw+B734NzzoFjjknnrxIR0T2Cehk3zl/aOcglndxc+I//gPfegz/8Ad7f1oZvTx7At8oW8QDXcjs3UcQpvqqLCRP8ewsTJvj3GPr1g6lTaffGG6ryVESqzZrln06pR8WZidIZQQrl5sK118KVV/ozhGnTujGRPwCO7BZVzOyTxZgxkHXvvf49huefh3/8A+65hxMrKvzN6rPPhu9+128A7dtn+ieJSDrt2OH3DbNm+WfWwV9WhqTeY1QiSINWrXxC2LEDfvlLcM6oqMriqqv8fehvfxtGjOjNiB/25ivXXw87d7L+d7+j7/vvw4IF8NhjkJ3tm0z73vdg71749791w1kkHWbNqn1JOJm++AI2buSIl16CZcv8jj/clZTEXuapp5QImqtvf9tXXFdeDjk5vq2DzZt9gn/yST/P8cfDiBEd6NbtfI5+sB95rSt9vUjPPefPFm64obrARYvg1luhZ0847LDEu7w8/+LDSy/5M43LLvNtcebmVn/m5Pi35+oyaxb5Dz8MP/lJwzfKVP+TiSSqvBw++aRmN38+PPusn75oka+W5pvfhNat/RHewT7D/fPm+X/yAQP8y6uRO/sPPwSgbziO7t2hd2//MErv3r77v//z7zWFhSrSTBZzzeyh90GDBrmVKxvWxn1hYSEFBQXJDaieiop85XUFBTBkiB/nnK8Hb9Ei3xUW+moscnL8NjdihO9OOAGyhp3uzwbCunSB/v39WUKsrjH3GXJyfGKIThItW8KePbBlC45Q9d75+fD1r/vp4X+AcH+8z5deggcfrP6+u++G667z05MsLX/7ZCS1WbPY8fDDdGxMcm2sBH/HgXXqHJSV+WrdS0v9dvf44/4pu+HD/RN3kdtPdH+8A46GrE/n/DZfUeG7Rx7h80cf5fBzzvH/TJE7+W3bag5//nn911VDdejgj/rCO/revVm5ezeDLr44/lOEjdy+zGyVc25QzGlKBE1PWRlMn76GTz8dcOApU/APKH2713t8ddVfKaclP+Bphj40Jv5G4Zw/ygn/c4a7a66ByHXYty9MnOi/uLzcd+H+eJ///jd89ll1GW3b+iOZfft8V1ZW3V/fbax1azj88Npdx46xx7/wArz4Ipx1FlxySXU9IBGfryxbxtDTTqs1HjPfzZnjj/bOPhsuvtj/xv37q9dH9HD0tMWL/c4v7KyzoE8fn9HD6+Fg/bt3w5dfVifXrl39+yfxzupijQtfXjjtNP9bwjvEyJ1jXf3//veB9jsA/0Tb0UdXb0PhnX1pKWWff05uePuqqqrf3zhSVlbt5PDllzW3r65d/W+Mjjm6S/TAp107X+aRR/rPWN2RR/oz8euuq17uoYfgiivi/w1jfd5zjz/SCysogH/9q7ryspBU75+UCEKaSyKAmrF++qnfz73wgt8ut28Pz+Xo3dsYPNjvc/r29d0xxxzkqk6oxbYDHnqo/kcYoTIO7LTileGc/wcNJ4bIz7/8Bf77v6vnveQS/0M+/zx+t2dP/eLMpMMOq3l5ILo/etz//q9/kz2sa1cYOLA6gUcn9LKy1P+G7Gzo1q068eTlHej/eM8euh13XK3x3HcfvP56dRn9+8PUqbEPKuIdaPzzn/6IPezII/211ezs2l1WVj6PLuoAAA5/SURBVOzxjz7qL72EDR4Mf/2rP4tu3TrxddDYM70E/98ymQh0j6AZ6NLF7yMvucQ3mXnLLf4AzMyoqvLVIT32WPX8rVvD//t/1YkhnCQOJIhx4yh6rwuFT++g4LyODBl3bv2DCm3Inx/sMoaZv8SUk1P7lPfXv/aNA9Xnn6yiAnburE4M11zjm48L69vX30epqvJJKPT5zltv0fu442qNp6rK/6NG7jD69PF38cOXxSIvkUUPh/uffNI3ZReWjOR66611l1FRUTMxXHaZv58UdtJJ8Pvf195ZRu84I4cfe8xXuhg2fXrcGN4uLKRbrB1XRUXNHd9//AdcdFE9VgS1d56/+lX912fHjjXX59ix/uymvsaNa9xlunjvIDUlzrlm1Q0cONA11JIlSxq8bLrFi3XZMudat3YuK8t/Llvmx+/c6fsffti56693bsQI57p3d87v7XzXpo1zAwc6N3Kkczk5zrVo4VxurnMLFyY/zrR56KGaP/Khh2LOVmecCZaRUCwjRjR8+VAZJYMGNayMNP+Og67TJKyLjK7PNEv1/xKw0sXZr2Z8x17fLuiJwDm/w7/99uokUJfPP69OEJMm+f+rdu1q7i/Aj8vPd+7733du4kTn7r3Xuaeecm7VKudKSpyrqoodx1VXvZdQHCmVwA7joH/7ZOx0kqRR22kaf0dz+X9SnF5diUCXhpqhIUOqnzg6mA4das9fVOQf5igv91cFxo3zV3A2b/YvOS9ZUvtSfF6ev7QU7pzzjfPs39+Lxx/3l7czdvulsafuySqjKThUfoeklRJBAA0Z4h9yiX6MNcw5fxl+82bfffBBzf6XX/bTPWPfPv9wSYcO/p5euOvWreZwuOvcufpmdqzHaUUkvZQIAqquswqz6iczTzgh9jyLFsH3vw/l5Y7sbGPsWH/PdNs2+Phj/3Tqtm3+QZdoWVn+gZi8PNi40d+vzc729zrz8/33duhQ8wnRDh2gTZtaT9wBSiYijaVEIA0yYoS/hDR79vuMHXts3B1waalPCNHdxx/7M4vw4+cVFb4i1rrk5NRMDIcf7h8bX7LEf2Znw+TJ/mGZ6FcODvaUtJKJBJkSgTTYkCFQVraFIUOOjTtPXh587Wu+ixZ5r6JlS1+xa58+NZ8OjeyPHt6+3TcxXVHhy9u/31fhEUt29ukx30fr2LH6RdiKCp9sfvEL/+h7vJoDwv25uTXPUJKRTIqKYO7cr5Cbq4Qk6ZPSRGBmI4H7gCzgEefcnVHTLTT9bOALYIxzbnWtguSQFO9eRadOiZcRnUwef9zX5h2ZPHbsgLVrP6Rt26MPjPv0U3j77ep5wsrL4ec/T/z7w8khK8vXD+acTw75+f7yV2TiCPfH6z74wCeh8vJePPaYr8L8xBN9csrOrn4dI95wVlbyklFTKEPSJ2WJwMyygOnAd4BiYIWZzXfOvRkx21nAcaFuMDAj9CkBUZ8noOItX9eN77DCwvcpKIj9MtErr8B3vlNdGeAjj/hqYCJrCYhVc0Bk//Ll1W98O+dri2jVyl8GC88b2dV9qcooK/N1+TVG+L5KOFmE33+L7KLH7d7taz+oqvI39H/wA//OX/RyOTmweXN31q+vPX7TJpg2rfoM6ze/8c1stGhRu8vKij9u7Vp47TX/QvCJJ4bWTMQZWPT9oljTVq2CJ5/sRWkpnHJKdQINvz8XrmWkLulMjFVV/jJnuBaNcH9lqO7JlSth5MjkJ9dUnhGcDGx0zm0CMLN5wCggMhGMAv4cesZ1uZl1MLNuzrmPUxiXHGIam0yGDk0smdQl+sxk7tz45bhQFVCRCeXLL+HVV/2L0uXljpYtjf/+b39Jbf9+v1PYv792f+RwYaHvwmclvXv7HXB4vnAVSZHd3r01hz/5pLq6nspKX6VJVlb19JoJ7LiDrpeyspovKmfG0cybF39qZGKI7q+ogK1bq9dpz54+wUPNN3GihyPH7dvnq00Kj2vf3pcVuZP3O/2Cg/4SM1834+LFyU0GqUwE3YEPI4aLqX20H2ue7kCNRGBm44BxAF27dqWwsLBBAZWWljZ42XRrLrEeSnH6ex5+Z9oQd9/djjVrOjBgwE7KynbXu5xeveDee9vx2mutOfnkL+nbd3e9lu/UqR3LlvVn/34jJ8dx2WVr613G+vXt+OlPq8u4556aZfgdVwsqKoxdu74gNzfvwHBlpVFRYbz9dh733vt1KiuNrCzHtde+y9FHf4FzFqrZw6iqiuyv/gyPf/nlzhQWdsE5w8xx+umfMWRIdd38tc+orNa05cs78u9/H3GgjFNOKeGEE3ZSWVkda7g/uquoaEFlpbFx42E4lwcYzjmysvbSvfsXmFUHEK630Pe7WuM2bWrDp5+2DcXoOOqo3Xz963vIynKhsyBHVpajoqKM1q1zQmdFjhYtqrvVqzuwfHlnnDPKyqqYPXszZWUR9VI1Vrw3zRrbARfg7wuEh0cDD0TN8zxwasTwYmBgXeXqzeKmRXEmX2Nirc9b540tI1lvv8dbPlZVKg0po0WLykaXkYw4DlbGwdZnY+MgQ28WFwM9I4Z7AFsbMI+IJKixl8maShmJ3vtJpIzZszfX+YhzuuLIdBl1SWUiWAEcZ2a9gI+Ai4FLouaZD0wI3T8YDOxyuj8gIiQvIR3sEed0xdEUyognZYnAOVdhZhOAhfjHR2c759ab2fjQ9JnAAvyjoxvxj49ekap4REQktpS+R+CcW4Df2UeOmxnR74BrUxmDiIjU7SCtk4uIyKFOiUBEJOCUCEREAk6JQEQk4MwdrH7eJsbMPgM+aODinYHtSQwnlZpLrIoz+ZpLrIozuVId59HOuSNiTWh2iaAxzGylc25QpuNIRHOJVXEmX3OJVXEmVybj1KUhEZGAUyIQEQm4oCWCWZkOoB6aS6yKM/maS6yKM7kyFmeg7hGIiEhtQTsjEBGRKEoEIiIBd0gmAjMbaWZvm9lGM7spxnQzs/tD0183sxMzEGNPM1tiZhvMbL2Z1WrQz8wKzGyXma0Jdb9Id5wRsWw2szdCcayMMb0prNPjI9bVGjPbbWaToubJyDo1s9lm9qmZrYsY19HMXjCzd0Ofh8dZts7tOU2x3m1mb4X+tn83sw5xlq1zO0lDnNPM7KOIv+/ZcZZN2zqNE+dfI2LcbGZr4iybnvUZr8Wa5trhq7x+DzgWaAmsBfpEzXM28L/4tuNOAV7NQJzdgBND/W2Bd2LEWQA8l+l1GoplM9C5jukZX6cxtoNt+JdoMr5OgdOBE4F1EeN+A9wU6r8JuCvO76hze05TrCOA7FD/XbFiTWQ7SUOc04DJCWwbaVunseKMmn4v8ItMrs9D8YzgZGCjc26Tc64cmAeMippnFPBn5y0HOphZt3QG6Zz72Dm3OtS/B9iAb6+5ucr4Oo0yHHjPOdfQt9CTyjm3FNgRNXoU8KdQ/5+Ac2Msmsj2nFSxYnXOLXLOVYQGl+NbE8yoOOs0EWldp3XFaWYGXAg8karvT8ShmAi6Ax9GDBdTewebyDxpY2bHACcAr8aYPMTM1prZ/5pZ37QGVpMDFpnZKjMbF2N6k1qn+Bbx4v1zNZV12tWFWuQLfXaJMU9TW68AY/Fnf7EcbDtJhwmhS1iz41xua0rr9DTgE+fcu3Gmp2V9HoqJwGKMi35GNpF50sLM8oCngEnOud1Rk1fjL230Bx4Ankl3fBGGOudOBM4CrjWz06OmN6V12hL4PvBkjMlNaZ0mosmsVwAzuxmoAObGmeVg20mqzQC+CgwAPsZfdonWlNbpj6j7bCAt6/NQTATFQM+I4R7A1gbMk3JmloNPAnOdc09HT3fO7XbOlYb6FwA5ZtY5zWGGY9ka+vwU+Dv+9DpSk1inIWcBq51zn0RPaErrFPgkfPks9PlpjHmazHo1s8uB7wKXutAF7GgJbCcp5Zz7xDlX6ZyrAh6O8/1NYp2aWTZwHvDXePOka30eiolgBXCcmfUKHRleDMyPmmc+cFnoSZdTgF3hU/R0CV0b/COwwTn32zjzHBmaDzM7Gf/3KklflAfiOMzM2ob78TcO10XNlvF1GiHuUVZTWach84HLQ/2XA8/GmCeR7TnlzGwkMAX4vnPuizjzJLKdpFTUfakfxPn+JrFOgW8DbznnimNNTOv6TPXd6Ex0+CdY3sE/GXBzaNx4YHyo34DpoelvAIMyEOOp+NPR14E1oe7sqDgnAOvxTzUsB76ZofV5bCiGtaF4muQ6DcXRBr9jbx8xLuPrFJ+YPgb2449IrwQ6AYuBd0OfHUPzHgUsqGt7zkCsG/HX1cPb6szoWONtJ2mO87HQ9vc6fufeLdPrNFacofFzwttlxLwZWZ+qYkJEJOAOxUtDIiJSD0oEIiIBp0QgIhJwSgQiIgGnRCAiEnBKBCJpFKr99LlMxyESSYlARCTglAhEYjCzH5vZa6F64B8ysywzKzWze81stZktNrMjQvMOMLPlEXX1Hx4a/zUzezFUwd1qM/tqqPg8M/tbqH7/ueE3nUUyRYlAJIqZ/T/gInyFXwOASuBS4DB8HUYnAi8Bvwwt8mdginMuH/9Wa3j8XGC68xXcfRP/din4mmYnAX3wb48OTfmPEqlDdqYDEGmChgMDgRWhg/XW+ArhqqiuIOxx4Gkzaw90cM69FBr/J+DJUB0x3Z1zfwdwzu0DCJX3mgvVLxNqmeoY4OXU/yyR2JQIRGoz4E/Ouak1RprdEjVfXfWz1HW5pyyivxL9H0qG6dKQSG2LgfPNrAscaFv4aPz/y/mheS4BXnbO7QI+N7PTQuNHAy8537ZEsZmdGyoj18zapPVXiCRIRyIiUZxzb5rZz/EtQ7XA1xp5LbAX6Gtmq4Bd+PsI4KuQnhna0W8CrgiNHw08ZGa3hsq4II0/QyRhqn1UJEFmVuqcy8t0HCLJpktDIiIBpzMCEZGA0xmBiEjAKRGIiAScEoGISMApEYiIBJwSgYhIwP1/JvIFjoxGJrMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#모델 정의 \n",
    "#첫번째 은닉층 (출력뉴런수 512, 활성화함수 relu)\n",
    "#출력층 (출력뉴런수 10, 활성화함수 softmax)\n",
    "#오차함수 : categorial_crossentroy\n",
    "#최적화 함수\n",
    "#다중 분류 평가 측정 지표 accuracy\n",
    " \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "#모델 실행 결과 model폴더에 파일로 저장\n",
    "#학습 중단 설정\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    " \n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    " \n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "#학습 정확도와 테스트셋 오차를 시각화\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컨볼루션 신경망(Convolutional Neural Network,CNN)\n",
    "\n",
    "- 기본 딥러닝 프레임에 이미지 인식 분야에서 강력한 성능을 보이는 신경망\n",
    "- 입력된 이미지에서 다시 특징을 추출하기 위해 마스크(필터,윈도 또는 커널)를 도입하는 기법\n",
    "- 입력층과 출력층 사이의 중간층(은폐층)에 합성곱과 폴링층 배치한 것\n",
    "- 이미지를 흐리게만들거나 경계를 강조하는 작업 함\n",
    "- 합성곱층과 풀링층에서는 해상도를 낮추거나 샘플링하는 처리를 계속 함\n",
    "- 특징을 추출하는 기능을 하는 필터와 필터 값을 비선형 값으로 바꾸어 주는 Activation 함수로 구성\n",
    "\n",
    "- 합성곱층(컨볼루션)은 이미지의 특징을 추출할 때 사용\n",
    "- 입력 x의 일부분을 조금씩 자르면서 평활화와 윤곽선 검출 처리를 하며, 특징 맵 c 추출\n",
    "- 합성곱층의 역할은 주변의 값과 필터를 사용해 중앙에 있는 값을 변화 시키는 것\n",
    "- 평활화: 명암의 분포가 균일하지 못한 이미지에 적용해 분포를 균일하게 만들어주는 것\n",
    "- 폴링층: 합성곱층으로 얻은 특징맵 x를 축소하는 층\n",
    "\n",
    "- 컨볼루션 층을 추가 하는 함수: Conv2D()\n",
    "    ex)model.add(Conv2D(32,kernel_size=(3,3),input_shape=(28,28,1),activation='relu'))\n",
    "    \n",
    "\n",
    "#### 맥스 풀링(max pooling)\n",
    "\n",
    ": Actication map을 M * N의 크기로 자른후, 그안에서 가장 큰 값을 뽑아내는 방법\n",
    "\n",
    "풀링,서브 샘플링: 컨볼루션 층을 통해 이미지 특징 도출 결과가 여전히 크고 복잡하면 다시 축소하는 과정\n",
    "- 맥스 풀링: 정해진 구역안에서 가장 큰 값만 다음 층으로 넘기고 나머지는 버림\n",
    "- sampling을 통해서 연산에 들어가는 컴퓨팅 리소스가 적아지고 데이타의 크기를 줄이면서 소실이 발생하기 때문에, 오버피팅 방지\n",
    "\n",
    "* 컨볼루셔널 레이어: 컨볼루셔널 필터와 액티베이션 함수(ReLU) 그리고 풀링 레이어를 반복적으로 조합하여 특징 추출\n",
    "* Fully connected Layer: 컨볼루셔널 계층에서 특징이 추출이 되었으면 이 추출된 특징 값을 기존의 뉴럴 네트워크에 넣어서 분류\n",
    "\n",
    "\n",
    "### 컨볼루션 신경망 - 과적합 피하기\n",
    "\n",
    "- 드롭아웃(drop out)기법: 은닉층에 배치된 노드 중 일부를 임의로 꺼주는 것\n",
    "- 랜덤하게 노드를 끔으로써 학습 데이터에 지나치게 치우쳐서 학습되는 과적합 방지 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05221, saving model to ./model/01-0.0522.hdf5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.optimizers' has no attribute 'TFOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d701e3c3eb74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#정확도 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    717\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1150\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[1;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0msave_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    539\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0m_serialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# write as binary stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[1;34m(model, h5dict, include_optimizer)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mlayer_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFOptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m             warnings.warn(\n\u001b[0;32m    165\u001b[0m                 \u001b[1;34m'TensorFlow optimizers do not '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'TFOptimizer'"
     ]
    }
   ],
   "source": [
    "###########CNN 실습##########################\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.python.keras.optimizers import TFOptimizer\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    " \n",
    "numpy.random.seed(0)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 데이터 로드\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "#정규화\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# 정답 label one-hot enconding\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "#모델 정의\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "#모델 구축 컴파일\n",
    "model.compile(loss='categorical_crossentropy',   optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#모델 실행 결과 model폴더에 파일로 저장\n",
    "#학습 중단 설정\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    "#정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "#학습셋 오차와 테스트셋 오차를 시각화\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "# plt.axis([0, 20, 0, 0.35])\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

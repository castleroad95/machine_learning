{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#특성 스케일 변환\n",
    "#MinMaxScaler은 0과 1에 모든 값을 있게 한다.\n",
    "feature=np.array([[-500.5],[-100.1],[0],[100.1],[900.9]])\n",
    "minmax_scale=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "#fit()은 특성의 최대, 최소 값을 계산 transform()은 특성의 스케일을 조정 \n",
    "scaled_feature=minmax_scale.fit_transform(feature)\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.76058269]\n",
      " [-0.54177196]\n",
      " [-0.35009716]\n",
      " [-0.32271504]\n",
      " [ 1.97516685]]\n",
      "평균: 0.0\n",
      "표준편차: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#특성 표준화 변환\n",
    "#StandardScaler은 특성 평균이 0 표준편차가 1이 되도록 변환 - 특성을 정규분포로 근사하게 스케일링 \n",
    "x= np.array([[-1000.1], [-200.2], [500.5], [600.6], [9000.9]])\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized = scaler.fit_transform(x)\n",
    "print(standardized)\n",
    "print(\"평균:\", round(standardized.mean()))\n",
    "print(\"표준편차:\", standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#QuantileTransformer은 데이터를 1000개의 분위로 나누어 0~1에 분포시킴, 이상치의 영향 줄임\n",
    "x= np.array([[-1000.1], [-200.2], [500.5], [600.6], [9000.9]])\n",
    "preprocessing.QuantileTransformer().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RobustScaler은 평균과 분산 대신 median과 quartile사용, 이상치에 영향 받지 않음\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70710678 0.70710678]\n",
      " [0.30782029 0.95144452]\n",
      " [0.07405353 0.99725427]\n",
      " [0.04733062 0.99887928]\n",
      " [0.95709822 0.28976368]]\n",
      "[[0.5        0.5       ]\n",
      " [0.24444444 0.75555556]\n",
      " [0.06912442 0.93087558]\n",
      " [0.04524008 0.95475992]\n",
      " [0.76760563 0.23239437]]\n",
      "첫 번째 샘플값의 합 :  1.0\n",
      "[[0.5        0.5       ]\n",
      " [0.24444444 0.75555556]\n",
      " [0.06912442 0.93087558]\n",
      " [0.04524008 0.95475992]\n",
      " [0.76760563 0.23239437]]\n",
      "[[0.70710678 0.70710678]\n",
      " [0.30782029 0.95144452]\n",
      " [0.07405353 0.99725427]\n",
      " [0.04733062 0.99887928]\n",
      " [0.95709822 0.28976368]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Normalizer은 row마다 각각 정규화됨\n",
    "features = np.array([[0.5, 0.5], [1.1, 3.4], [1.5, 20.2], [1.63, 34.4], [10.9, 3.3]])\n",
    "\n",
    "#L2->유클리드 거리가 1이 되도록 데이터를 조정함\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "normalizer.transform(features)\n",
    "features_l2_norm = Normalizer(norm=\"l2\").transform(features)\n",
    "print(features_l2_norm)\n",
    "\n",
    "#L1->맨하튼 거리계산(샘플 특성 값의 합을 1로 만듬\n",
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "print(features_l1_norm)\n",
    "\n",
    "print(\"첫 번째 샘플값의 합 : \", features_l1_norm[0, 0] + features_l1_norm[0, 1])\n",
    "features / np.sum(np.abs(features), axis=1, keepdims=True)\n",
    "features / np.sqrt(np.sum(np.square(features), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        ],\n",
       "       [0.32352941, 1.        ],\n",
       "       [0.07425743, 1.        ],\n",
       "       [0.04738372, 1.        ],\n",
       "       [1.        , 0.30275229]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#max:각 행의 최대값으로 행을 나눔\n",
    "features = np.array([[0.5, 0.5], [1.1, 3.4], [1.5, 20.2], [1.63, 34.4], [10.9, 3.3]])\n",
    "Normalizer(norm=\"max\").transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#특성 행렬\n",
    "features = np.array([[2, 3], [2, 3], [2, 3]]) \n",
    "\n",
    "# PolynomialFeatures 객체를 만듭니다.(교차항을 포함함)\n",
    "#degree 다항식의 최대 차수 결정\n",
    "#interaction_only->True로 지정할 시 교차항 특성만 만듬\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "#다항 특성 생성\n",
    "polynomial_interaction.fit_transform(features)\n",
    "interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'x0', 'x1', 'x0^2', 'x0 x1', 'x1^2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#include_bias 매개벼수의 변수값은 True(변환된 특성에 상수항 1 추가)\n",
    "polynomial_bias = PolynomialFeatures(degree=2, include_bias=True).fit(features)\n",
    "polynomial_bias.transform(features)\n",
    "polynomial_bias.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#FunctionTransformer을 사용 하여 특성에 함수 적용 가능\n",
    "features = np.array([[2, 3], [2, 3], [2, 3]])\n",
    "\n",
    "def add_ten(x): \n",
    "    return x + 10\n",
    "\n",
    "#변환기 객체 생성\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pandas의 apply()를 사용하여 동일 변환 수행 가능\n",
    "df = pd.DataFrame(features, columns=['feature_1', 'feature_2'])\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12, 103],\n",
       "       [ 12, 103],\n",
       "       [ 12, 103]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#validate 매개변수가 True이면 입력값이 2차원 배열인지 확인 후 아닐 경우 예외 발생\n",
    "#validate 매개변수가 False이면 1차원 배열에도 적용 가능\n",
    "\n",
    "def add_hundred(x):\n",
    "    return x + 100\n",
    "\n",
    "#Columntransformer은 특성 배열이나 데이터프레임 열마다 다른 변환 적용 가능\n",
    "#(이름, 변환기, 열 리스트)로 구성된 튜플의 리스트를 ColumnTransformer에 전달\n",
    "ct = ColumnTransformer(\n",
    "[(\"add_ten\", FunctionTransformer(add_ten, validate=True), ['feature_1']),\n",
    "(\"add_hundred\", FunctionTransformer(add_hundred, validate=True), ['feature_2'])])\n",
    "ct.fit_transform(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

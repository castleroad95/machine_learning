{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN(K-최근접 이웃) 분류\n",
    "\n",
    "- 기술적으로 예측을 만들기 위해 모델을 훈련하지 않고 가장 가까운 k개의 샘플에서 다수의 클래스를 그 샘플의 클래스로 예측\n",
    "- 분류(classification)알고리즘 으로 유사한 특성을 가진 데이터는 유사한 범주에 속하는 경행이 있다고 가정\n",
    "- KNN사용시 모든 특성을 고르게 반영하기 위해 정규화 진행\n",
    "    * 최소값을 0, 최대값을 1로 고정한 뒤 모든 값을 0과 1사이 값으로 변환\n",
    "    * 평균과 표준편차를 활용해서 평균으로부터 얼마나 떨어져 있는지 z-점수로 변환\n",
    "- K 개수 선택- 모든 값을 실제로 테스트 하면서 분류 정확도를 계산 하는 과정에서 발견가능\n",
    "- KNN은 주변 다른 이웃까지 충분히 고려하지 않았을 때 오버피팅 발생\n",
    "- k가 너무 큰경우 underfiting(과소적합)발생, 너무 작은경우 overfiting발생\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플의 최근접 이웃찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#샘플의 최근접 이웃찾기\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "standardizer = StandardScaler() # 표준화 객체 생성\n",
    "features_standardized = standardizer.fit_transform(features) # 특성을 표준화\n",
    "\n",
    "# k=2인 최근접 이웃 모델 생성\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=2).fit(features_standardized)\n",
    "new_observation = [ 1, 1, 1, 1] #New Sample Data\n",
    "\n",
    "# New 샘플과 가장 가까운 이웃의 인덱스와 거리 탐색\n",
    "distances, indices = nearest_neighbors.kneighbors([new_observation])\n",
    "features_standardized[indices] # 최근접 이웃을 확인\n",
    "\n",
    "nearestneighbors_euclidean = NearestNeighbors( n_neighbors=2, metric='euclidean').fit(features_standardized)\n",
    "distances # 거리 확인\n",
    "\n",
    "# 유클리디안 거리를 기반으로 각 샘플에 대해 (자기 자신을 포함한) 세 개의 최근접 이웃 탐색\n",
    "nearestneighbors_euclidean = NearestNeighbors(n_neighbors=3, metric=\"euclidean\").fit(features_standardized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 샘플의 (자기 자신을 포함한) 3개의 최근접 이웃을 나타내는 리스트의 리스트\n",
    "nearest_neighbors_with_self = nearestneighbors_euclidean.kneighbors_graph( features_standardized).toarray()\n",
    "# 최근접 이웃 중에서 1로 표시된 자기 자신 제외\n",
    "for i, x in enumerate(nearest_neighbors_with_self ):\n",
    "    x[i] = 0\n",
    "\n",
    "# 첫 번째 샘플에 대한 두 개의 최근접 이웃 확인\n",
    "nearest_neighbors_with_self[0]\n",
    "\n",
    "# 이 샘플과 가장 가까운 이웃의 다섯개의 인덱스 탐색\n",
    "indices = nearest_neighbors.kneighbors([new_observation], n_neighbors=5, return_distance=False)\n",
    "features_standardized[indices] # 최근접 이웃을 확인\n",
    "\n",
    "# 반경 0.5 안에 있는 모든 샘플의 인덱스 탐색\n",
    "indices = nearest_neighbors.radius_neighbors( [new_observation], radius=0.5, return_distance=False)\n",
    "features_standardized[indices[0]] # 반경 내의 이웃 확인\n",
    "\n",
    "# 반경 내의 이웃을 나타내는 리스트의 리스트\n",
    "nearest_neighbors_with_self = nearest_neighbors.radius_neighbors_graph( [new_observation], radius=0.5).toarray()\n",
    "nearest_neighbors_with_self[0] # 첫 번째 샘플에 대한 반경 내의 이웃 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-최근접 이웃 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-최근접 이웃 분류기\n",
    "#클래스를 모르는 샘플이 주어졌을 때 이웃한 샘플 클래스 기반으로 샘플 클래스 예측\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "standardizer = StandardScaler() # 표준화 객체\n",
    "X_std = standardizer.fit_transform(X) # 특성을 표준화\n",
    "\n",
    "# 5개의 이웃을 사용한 KNN 분류기 훈련\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)\n",
    "new_observations = [[ 0.75, 0.75, 0.75, 0.75],\n",
    "    [ 1, 1, 1, 1]] # 두 개의 샘플을 만듬\n",
    "\n",
    "knn.predict(new_observations) # 두 샘플의 클래스를 예측\n",
    "knn.predict_proba(new_observations) # 각 샘플이 세 클래스에 속할 확률을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32440.000000000004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston() # 데이터 로드\n",
    "features = boston.data[:,0:2] #두 개의 특성만 선택\n",
    "target = boston.target\n",
    "\n",
    "# 최근접 회귀 모델 객체 생성\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=10)\n",
    "model = knn_regressor.fit(features, target) # 모델 훈련\n",
    "# 첫 번째 샘플의 타깃 값을 예측하고 1000을 곱함\n",
    "model.predict(features[0:1])[0]*1000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "indices = model.kneighbors(features[0:1], return_distance=False)\n",
    "np.mean(target[indices]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최선의 이웃 개수 결정\n",
    "\n",
    "- KNN 분류기에 각기 다른 k값으로 5-폴드 교차검증을 수행하는 GridSerarchCV사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "standardizer = StandardScaler() # 표준화 객체 생성\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1) # KNN 분류기 객체 생성\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"knn\", knn)]) # 파이프라인 생성\n",
    "\n",
    "# 탐색 영역의 후보를 만듭니다.\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "classifier = GridSearchCV( pipe, search_space, cv=5, verbose=0).fit(features, target)\n",
    "\n",
    "# 최선의 이웃 개수 (k)\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반지름 기반의 최근접 이웃 분류기(RadiusNeighborsClassifier)\n",
    "\n",
    "- 샘플의 클래스가 주어진 반지름 r 이내에 있는 모든 샘플의 클래스로 부터 예측\n",
    "- radius 매개변수로 고정 영역의 반지름을 지정하여 이웃 샘플 결정\n",
    "- outlier_lavel 매개변수는 반지름 내에 다른 샘플이 하나도 없는 샘플에 부여할 레이블 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:566: UserWarning: Outlier label -1 is not in training classes. All class probabilities of outliers will be assigned with 0.\n",
      "  ''.format(self.outlier_label_[k]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "i\n",
    "ris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "standardizer = StandardScaler() # 표준화 객체 생성\n",
    "features_standardized = standardizer.fit_transform(features) # 특성을 표준화\n",
    "\n",
    "# 반지름 이웃 분류기를 훈련합니다.\n",
    "rnn = RadiusNeighborsClassifier( radius=.5, n_jobs=-1).fit(features_standardized, target)\n",
    "new_observations = [[ 1, 1, 1, 1]] # 두 개의 샘플을 만듭니다.\n",
    "rnn.predict(new_observations) # 두 샘플의 클래스를 예측\n",
    "\n",
    "# 반지름 이웃 분류기를 훈련합니다.\n",
    "rnn = RadiusNeighborsClassifier( radius=.5, outlier_label=-1, n_jobs=-1).fit(features_standardized, target)\n",
    "rnn.predict([[100, 100, 100, 100]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
